{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningTutorial_ConvolutionalNeuralNetwork.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "FDkTm7fyGFhl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "c6d0d746-4cbe-4dcb-e945-fff360727e85",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1524081517857,
          "user_tz": 360,
          "elapsed": 2753991,
          "user": {
            "displayName": "Esteban Guillen",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "106714419202511485831"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True, reshape=False)\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 20\n",
        "batch_size = 100\n",
        "\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=[None, 28, 28, 1], name=\"input\")\n",
        "\n",
        "Y_ = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
        "\n",
        "step = tf.placeholder(tf.int32)\n",
        "\n",
        "\n",
        "\n",
        "def weight_variable(shape):\n",
        "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def bias_variable(shape):\n",
        "  initial = tf.constant(0.1, shape=shape)\n",
        "  return tf.Variable(initial)\n",
        "\n",
        "def conv2d(x, W):\n",
        "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "def max_pool_2x2(x):\n",
        "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
        "                        strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "\n",
        "W_conv1 = weight_variable([5, 5, 1, 32])\n",
        "b_conv1 = bias_variable([32])\n",
        "\n",
        "\n",
        "h_conv1 = tf.nn.relu(conv2d(X, W_conv1) + b_conv1)\n",
        "h_pool1 = max_pool_2x2(h_conv1)\n",
        "\n",
        "W_conv2 = weight_variable([5, 5, 32, 64])\n",
        "b_conv2 = bias_variable([64])\n",
        "\n",
        "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
        "h_pool2 = max_pool_2x2(h_conv2)\n",
        "\n",
        "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
        "b_fc1 = bias_variable([1024])\n",
        "\n",
        "\n",
        "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
        "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
        "\n",
        "W_fc2 = weight_variable([1024, 10])\n",
        "b_fc2 = bias_variable([10])\n",
        "\n",
        "Ylogits = tf.matmul(h_fc1, W_fc2) + b_fc2\n",
        "Y = tf.nn.softmax(Ylogits)\n",
        "\n",
        "\n",
        "loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=Ylogits, labels=Y_)\n",
        "loss = tf.reduce_mean(loss)*100\n",
        "\n",
        "\n",
        "# training step, the learning rate is a placeholder\n",
        "# the learning rate is: # 0.0001 + 0.003 * (1/e)^(step/2000)), i.e. exponential decay from 0.003->0.0001\n",
        "lr = 0.0001 +  tf.train.exponential_decay(0.003, step, 2000, 1/math.e)\n",
        "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
        "\n",
        "\n",
        "\n",
        "correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "display_step = 1\n",
        "n_iterations = []  \n",
        "n_loss = []\n",
        "n_loss_test = []\n",
        "n_train_accuracy = []\n",
        "n_test_accuracy = []\n",
        "\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    total_steps = 0;\n",
        "    \n",
        "    for epoch in range(training_epochs):\n",
        "        avg_cost = 0.\n",
        "        avg_accuracy = 0.\n",
        "        avg_accuracy_test = 0.0\n",
        "        total_batch = int(mnist.train.num_examples/batch_size)\n",
        "        \n",
        "        for i in range(total_batch):\n",
        "            total_steps = total_steps +1\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            \n",
        "            \n",
        "            #Train\n",
        "            sess.run(train_step, feed_dict={X: batch_xs, Y_: batch_ys, step: total_steps})\n",
        "           \n",
        "            #Evaluate\n",
        "            train_accuracy, c = sess.run([accuracy,loss],feed_dict={X: batch_xs, Y_: batch_ys})\n",
        "            test_accuracy, c_test = sess.run([accuracy,loss],feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
        "          \n",
        "            avg_cost += c / total_batch\n",
        "            avg_accuracy += train_accuracy /total_batch\n",
        "            avg_accuracy_test += test_accuracy /total_batch\n",
        "            \n",
        "            n_iterations.append(total_steps)\n",
        "            n_loss.append(c)\n",
        "            n_loss_test.append(c_test)\n",
        "            n_train_accuracy.append(train_accuracy)\n",
        "            n_test_accuracy.append(test_accuracy)\n",
        "        \n",
        "        \n",
        "        if (epoch+1) % display_step == 0 or epoch == 0:\n",
        "            print(\"Epoch:\", '%04d' % (epoch+1), \" Cost=\", \"{:.9f}\".format(avg_cost), \" Train_Accuracy=\", \"{:.9f}\".format(avg_accuracy),\" Test_Accuracy=\", \"{:.9f}\".format(avg_accuracy_test))\n",
        "            \n",
        "\n",
        "    print(\"Training Finished!\")\n",
        "\n",
        "    \n",
        "    \n",
        "    final_test_accuracy = sess.run(accuracy,feed_dict={X: mnist.test.images, Y_: mnist.test.labels})\n",
        "    print(\"\\nTest_Accuracy:\", final_test_accuracy)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n",
            "Epoch: 0001  Cost= 35.876851542  Train_Accuracy= 0.921363641  Test_Accuracy= 0.920525273\n",
            "Epoch: 0002  Cost= 5.231365057  Train_Accuracy= 0.984363647  Test_Accuracy= 0.979543636\n",
            "Epoch: 0003  Cost= 3.327835022  Train_Accuracy= 0.990127281  Test_Accuracy= 0.983641636\n",
            "Epoch: 0004  Cost= 2.412056592  Train_Accuracy= 0.992636370  Test_Accuracy= 0.985661455\n",
            "Epoch: 0005  Cost= 1.704739505  Train_Accuracy= 0.995163641  Test_Accuracy= 0.986325091\n",
            "Epoch: 0006  Cost= 1.265047532  Train_Accuracy= 0.996600003  Test_Accuracy= 0.987440000\n",
            "Epoch: 0007  Cost= 0.955304487  Train_Accuracy= 0.997509093  Test_Accuracy= 0.987713820\n",
            "Epoch: 0008  Cost= 0.683852998  Train_Accuracy= 0.998363638  Test_Accuracy= 0.988266363\n",
            "Epoch: 0009  Cost= 0.475258923  Train_Accuracy= 0.999127274  Test_Accuracy= 0.988146001\n",
            "Epoch: 0010  Cost= 0.372490805  Train_Accuracy= 0.999254546  Test_Accuracy= 0.988407273\n",
            "Epoch: 0011  Cost= 0.278833058  Train_Accuracy= 0.999545455  Test_Accuracy= 0.988500545\n",
            "Epoch: 0012  Cost= 0.212878665  Train_Accuracy= 0.999672728  Test_Accuracy= 0.988258363\n",
            "Epoch: 0013  Cost= 0.173709571  Train_Accuracy= 0.999800000  Test_Accuracy= 0.988104364\n",
            "Epoch: 0014  Cost= 0.143159490  Train_Accuracy= 0.999763637  Test_Accuracy= 0.988326181\n",
            "Epoch: 0015  Cost= 0.114298241  Train_Accuracy= 0.999909091  Test_Accuracy= 0.988145456\n",
            "Epoch: 0016  Cost= 0.094657562  Train_Accuracy= 0.999927273  Test_Accuracy= 0.988230546\n",
            "Epoch: 0017  Cost= 0.080825340  Train_Accuracy= 0.999945455  Test_Accuracy= 0.987993819\n",
            "Epoch: 0018  Cost= 0.070213076  Train_Accuracy= 0.999963636  Test_Accuracy= 0.987991636\n",
            "Epoch: 0019  Cost= 0.059216410  Train_Accuracy= 1.000000000  Test_Accuracy= 0.987935271\n",
            "Epoch: 0020  Cost= 0.049816510  Train_Accuracy= 1.000000000  Test_Accuracy= 0.988082546\n",
            "Training Finished!\n",
            "\n",
            "Test_Accuracy: 0.9883\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hQpJbr_zvLUN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}